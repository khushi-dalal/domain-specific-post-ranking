{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdBW-PLSfk_p",
        "outputId": "5fda1ad9-03a0-4bb5-cc73-2673cf1453c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    channel_info  influence_score  rank        country\n",
            "0      cristiano        22.395805   1.0          Spain\n",
            "1    kyliejenner        21.659762   2.0  United States\n",
            "140          j.m        21.161378   3.0            NaN\n",
            "3    selenagomez        18.335557   4.0  United States\n",
            "2       leomessi        18.284884   5.0            NaN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Download stopwords if not already done\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the Instagram dataset\n",
        "df = pd.read_csv('/content/sample_data/top_insta_influencers_data.csv')  # Replace with your actual dataset path\n",
        "\n",
        "# Function to convert values like '3.3k' to 3300\n",
        "def convert_to_numeric(value):\n",
        "    if isinstance(value, str):\n",
        "        if 'k' in value:\n",
        "            return float(value.replace('k', '')) * 1000\n",
        "        elif 'm' in value:\n",
        "            return float(value.replace('m', '')) * 1000000\n",
        "        elif 'b' in value:\n",
        "            return float(value.replace('b', '')) * 1000000000\n",
        "        else:\n",
        "            try:\n",
        "                return float(value)\n",
        "            except ValueError:\n",
        "                return np.nan  # Handle cases that can't be converted\n",
        "    else:\n",
        "        return value  # If already numeric, return as is\n",
        "\n",
        "# Apply the conversion to the numerical columns\n",
        "for col in ['posts', 'followers', 'avg_likes', 'new_post_avg_like', 'total_likes']:\n",
        "    df[col] = df[col].apply(convert_to_numeric)\n",
        "\n",
        "\n",
        "# Normalize numerical columns\n",
        "def normalize_features(df, columns):\n",
        "    scaler = MinMaxScaler()\n",
        "    df[columns] = scaler.fit_transform(df[columns])\n",
        "    return df\n",
        "\n",
        "numerical_columns = ['posts', 'followers', 'avg_likes', 'new_post_avg_like', 'total_likes']\n",
        "df = normalize_features(df, numerical_columns)\n",
        "\n",
        "# TF-IDF Vectorization for influencer names\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['channel_info'].astype(str))\n",
        "\n",
        "# Combine features like Followers, Avg Likes, and Total Likes for similarity\n",
        "df['combined_features'] = df['followers'] + df['avg_likes'] + df['total_likes']  # Simple combination, can be weighted\n",
        "combined_matrix = np.hstack((tfidf_matrix.toarray(), df[['followers', 'avg_likes', 'total_likes']].values))\n",
        "\n",
        "# Calculate cosine similarity\n",
        "cosine_sim_matrix = cosine_similarity(combined_matrix)\n",
        "\n",
        "# Sum cosine similarities for each influencer (indicates their influence)\n",
        "df['influence_score'] = cosine_sim_matrix.sum(axis=1)\n",
        "\n",
        "# Rank influencers by influence score\n",
        "df['rank'] = df['influence_score'].rank(ascending=False)\n",
        "\n",
        "# Display top-ranked influencers\n",
        "top_influencers = df[['channel_info', 'influence_score', 'rank', 'country']].sort_values(by='rank')\n",
        "print(top_influencers.head())\n"
      ]
    }
  ]
}