{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctWGCDfBG3ua",
        "outputId": "4174fbf7-09b9-4565-c72d-3ff589c06029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ce8d0647f2af>:31: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df[['FOLLOWERS', 'ER']] = df[['FOLLOWERS', 'ER']].applymap(convert_to_numeric)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated Rankings - Key Influencers:\n",
            "                                  NAME   final_score  predicted_rank\n",
            "0           Virat Kohli\\n@virat.kohli  1.620001e+08             1.0\n",
            "1        Narendra Modi\\n@narendramodi  5.544010e+07             2.0\n",
            "2           Alia Bhatt üíõ\\n@aliaabhatt  5.172010e+07             3.0\n",
            "3          Katrina Kaif\\n@katrinakaif  4.824010e+07             4.0\n",
            "4    ‡§¶‡•Ä‡§™‡§ø‡§ï‡§æ ‡§™‡§æ‡§¶‡•Å‡§ï‡•ã‡§£\\n@deepikapadukone  4.824010e+07             5.0\n",
            "..                                ...           ...             ...\n",
            "987         Mehak Sayal\\n@mehakgupta_  8.400998e+05           994.0\n",
            "966                 ALOK\\n@alokvmenon  8.400998e+05           994.0\n",
            "970         Sharwanand\\n@imsharwanand  8.400998e+05           994.0\n",
            "972            Itsmecutie\\n@nira_jain  8.400998e+05           994.0\n",
            "971     Actor Soori\\n@soorimuthuchamy  8.400998e+05           994.0\n",
            "\n",
            "[1000 rows x 3 columns]\n",
            "Total Execution Time: 197.2202 seconds\n",
            "Step 1 (Clustering): 0.0308 seconds\n",
            "Step 2 (CNN Training): 0.1039 seconds\n",
            "Step 3 (Similarity Calculation): 5.7686 seconds\n",
            "Step 4 (Graph Analysis): 191.3026 seconds\n",
            "Step 5 (Final Score Calculation): 0.0006 seconds\n",
            "Step 6 (Metrics Calculation): 0.0136 seconds\n"
          ]
        }
      ],
      "source": [
        "# ALL 3 SIMILARITIES\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import precision_score, accuracy_score, f1_score, recall_score\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/sample_data/insta dataset new - Sheet1.csv\")  # Ensure correct dataset path\n",
        "\n",
        "# Convert necessary columns to numeric (handling percentage ER)\n",
        "def convert_to_numeric(value):\n",
        "    if isinstance(value, str):\n",
        "        if '%' in value:\n",
        "            return float(value.replace('%', ''))\n",
        "        elif 'M' in value:\n",
        "            return float(value.replace('M', '')) * 1e6\n",
        "        elif 'K' in value:\n",
        "            return float(value.replace('K', '')) * 1e3\n",
        "        elif value == '-':\n",
        "            return np.nan\n",
        "    return value\n",
        "\n",
        "df[['FOLLOWERS', 'ER']] = df[['FOLLOWERS', 'ER']].applymap(convert_to_numeric)\n",
        "\n",
        "# Step 1: Clustering based on engagement metrics\n",
        "start_time = time.time()\n",
        "X = df[['FOLLOWERS', 'ER']].fillna(0)\n",
        "kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "df['cluster'] = kmeans.fit_predict(X)\n",
        "clustering_time = time.time() - start_time\n",
        "\n",
        "# Step 2: CNN Model for Feature Extraction\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(16 * (input_size // 2), num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "# Training CNN Model\n",
        "start_time = time.time()\n",
        "input_size = 2\n",
        "num_classes = 5\n",
        "model = CNNModel(input_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(50):\n",
        "    inputs = torch.randn(100, 1, input_size)\n",
        "    targets = torch.randint(0, num_classes, (100,))\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "cnn_time = time.time() - start_time\n",
        "\n",
        "# Step 3: Cosine & Jaccard Similarity Calculation\n",
        "start_time = time.time()\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(df['NAME'])\n",
        "\n",
        "# Cosine Similarity\n",
        "cosine_sim = cosine_similarity(tfidf_matrix)\n",
        "df['cosine_score'] = cosine_sim.mean(axis=1)\n",
        "\n",
        "# Jaccard Similarity\n",
        "def jaccard_similarity(a, b):\n",
        "    set_a = set(a.lower().split())\n",
        "    set_b = set(b.lower().split())\n",
        "    return len(set_a.intersection(set_b)) / len(set_a.union(set_b)) if len(set_a.union(set_b)) > 0 else 0\n",
        "\n",
        "df['jaccard_score'] = df['NAME'].apply(lambda x: np.mean([jaccard_similarity(x, y) for y in df['NAME']]))\n",
        "similarity_time = time.time() - start_time\n",
        "\n",
        "# Step 4: Common Neighbors Calculation (Graph-based similarity)\n",
        "start_time = time.time()\n",
        "G = nx.Graph()\n",
        "edges = [(df.iloc[i]['NAME'], df.iloc[j]['NAME']) for i in range(len(df)) for j in range(i + 1, len(df)) if i != j]\n",
        "G.add_edges_from(edges)\n",
        "\n",
        "def common_neighbors_score(node):\n",
        "    return np.mean([len(list(nx.common_neighbors(G, node, neighbor))) for neighbor in G.neighbors(node)]) if G.has_node(node) else 0\n",
        "\n",
        "df['common_neighbors'] = df['NAME'].apply(lambda x: common_neighbors_score(x))\n",
        "graph_time = time.time() - start_time\n",
        "\n",
        "# Step 5: Weighted Score Calculation\n",
        "start_time = time.time()\n",
        "df['weighted_score'] = df['FOLLOWERS']\n",
        "final_score_time = time.time() - start_time\n",
        "\n",
        "# Step 6: Final Score Calculation & Metrics\n",
        "start_time = time.time()\n",
        "df['final_score'] = (\n",
        "    (df['weighted_score'] * 0.6) +\n",
        "    (df['cosine_score'] * 0.16) +\n",
        "    (df['jaccard_score'] * 0.14) +\n",
        "    (df['common_neighbors'] * 0.1)\n",
        ")\n",
        "\n",
        "df['predicted_rank'] = df['final_score'].rank(ascending=False)\n",
        "df['actual_rank'] = df.index + 1\n",
        "\n",
        "top_10_percent = int(len(df) * 0.1)\n",
        "df['actual_top'] = df['actual_rank'] <= top_10_percent\n",
        "df['predicted_top'] = df['predicted_rank'] <= top_10_percent\n",
        "\n",
        "y_true = df['actual_top'].astype(int)\n",
        "y_pred = df['predicted_top'].astype(int)\n",
        "\n",
        "# Compute Metrics\n",
        "precision = precision_score(y_true, y_pred) * 100\n",
        "accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "f1 = f1_score(y_true, y_pred) * 100\n",
        "recall = recall_score(y_true, y_pred) * 100\n",
        "\n",
        "# Specificity Calculation\n",
        "tn = ((y_true == 0) & (y_pred == 0)).sum()\n",
        "fp = ((y_true == 0) & (y_pred == 1)).sum()\n",
        "specificity = (tn / (tn + fp)) * 100 if (tn + fp) > 0 else 0\n",
        "\n",
        "metrics_time = time.time() - start_time\n",
        "\n",
        "# Total Execution Time\n",
        "total_execution_time = clustering_time + cnn_time + similarity_time + graph_time + final_score_time + metrics_time\n",
        "\n",
        "# # Display the final rankings and metrics\n",
        "print(\"\\nUpdated Rankings - Key Influencers:\\n\", df[['NAME', 'final_score', 'predicted_rank']].sort_values(by='predicted_rank'))\n",
        "# print(f\"\\nPrecision: {precision:.2f}%\")\n",
        "# print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "# print(f\"F1-Score: {f1:.2f}%\")\n",
        "# print(f\"Recall: {recall:.2f}%\")\n",
        "# print(f\"Specificity: {specificity:.2f}%\\n\")\n",
        "\n",
        "# Display execution time breakdown\n",
        "print(f\"Total Execution Time: {total_execution_time:.4f} seconds\")\n",
        "print(f\"Step 1 (Clustering): {clustering_time:.4f} seconds\")\n",
        "print(f\"Step 2 (CNN Training): {cnn_time:.4f} seconds\")\n",
        "print(f\"Step 3 (Similarity Calculation): {similarity_time:.4f} seconds\")\n",
        "print(f\"Step 4 (Graph Analysis): {graph_time:.4f} seconds\")\n",
        "print(f\"Step 5 (Final Score Calculation): {final_score_time:.4f} seconds\")\n",
        "print(f\"Step 6 (Metrics Calculation): {metrics_time:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COMMON NEIGHBOURS\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import precision_score, accuracy_score, f1_score, recall_score, confusion_matrix\n",
        "import networkx as nx\n",
        "from numba import njit\n",
        "\n",
        "# Measure execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/sample_data/insta dataset new - Sheet1 (2).csv\")  # Update file path\n",
        "\n",
        "# Convert necessary columns to numeric\n",
        "def convert_to_numeric(value):\n",
        "    if isinstance(value, str):\n",
        "        value = value.replace(',', '')  # Remove commas\n",
        "        if '%' in value:\n",
        "            return float(value.replace('%', '')) / 100  # Convert percentage to decimal\n",
        "        elif 'M' in value:\n",
        "            return float(value.replace('M', '')) * 1e6\n",
        "        elif 'K' in value:\n",
        "            return float(value.replace('K', '')) * 1e3\n",
        "        elif value == '-':\n",
        "            return np.nan  # Handle missing values\n",
        "        try:\n",
        "            return float(value)\n",
        "        except ValueError:\n",
        "            return np.nan\n",
        "    return value\n",
        "\n",
        "df[['FOLLOWERS', 'ER']] = df[['FOLLOWERS', 'ER']].applymap(convert_to_numeric)\n",
        "\n",
        "# Clustering\n",
        "X = df[['FOLLOWERS', 'ER']].fillna(0)\n",
        "kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "df['cluster'] = kmeans.fit_predict(X)\n",
        "\n",
        "# ---- Optimized Graph-Based Common Neighbors Calculation ----\n",
        "G = nx.Graph()\n",
        "G.add_nodes_from(df['NAME'])\n",
        "\n",
        "# Create an adjacency matrix for faster lookup\n",
        "adj_matrix = np.zeros((len(df), len(df)), dtype=np.float64) # Change the data type to float64\n",
        "name_to_index = {name: i for i, name in enumerate(df['NAME'])}\n",
        "\n",
        "# Create graph edges efficiently\n",
        "for i in range(len(df)):\n",
        "    for j in range(i + 1, len(df)):  # Avoid redundant pairs\n",
        "        adj_matrix[i, j] = adj_matrix[j, i] = 1\n",
        "        G.add_edge(df.iloc[i]['NAME'], df.iloc[j]['NAME'])\n",
        "\n",
        "# Compute common neighbors using adjacency matrix\n",
        "@njit\n",
        "def compute_common_neighbors(matrix):\n",
        "    return np.dot(matrix, matrix)  # Fast matrix multiplication\n",
        "\n",
        "common_neighbors_matrix = compute_common_neighbors(adj_matrix)\n",
        "df['common_neighbors'] = [common_neighbors_matrix[i, :].sum() for i in range(len(df))]\n",
        "\n",
        "# Weighted Score Calculation\n",
        "df['weighted_score'] = (df['FOLLOWERS'] * 1) * (df['ER'] * 1)\n",
        "\n",
        "# Final Score Calculation\n",
        "df['final_score'] = (df['weighted_score'] * 0.5) + (df['common_neighbors'] * 0.5)\n",
        "\n",
        "# Rank influencers\n",
        "df['rank'] = df['final_score'].rank(ascending=False, method=\"dense\")\n",
        "\n",
        "# Define Top Influencers (Ground Truth & Prediction)\n",
        "top_10_percent = int(len(df) * 0.1)\n",
        "df['actual_top'] = df['ER'].rank(ascending=False, method=\"dense\") <= top_10_percent\n",
        "df['predicted_top'] = df['final_score'].rank(ascending=False, method=\"dense\") <= top_10_percent\n",
        "\n",
        "# Convert to binary labels\n",
        "y_true = df['actual_top'].astype(int)\n",
        "y_pred = df['predicted_top'].astype(int)\n",
        "\n",
        "# Compute Metrics\n",
        "precision = precision_score(y_true, y_pred)\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1])  # TN / (TN + FP)\n",
        "\n",
        "# Measure execution time\n",
        "execution_time = time.time() - start_time\n",
        "\n",
        "# Display results\n",
        "print(\"\\nUpdated Rankings - Key Influencers:\\n\", df[['NAME', 'final_score', 'rank']].sort_values(by='rank'))\n",
        "print(f\"\\nPrecision: {precision:.2%}\")\n",
        "print(f\"Accuracy: {accuracy:.2%}\")\n",
        "print(f\"F1-Score: {f1:.2%}\")\n",
        "print(f\"Recall: {recall:.2%}\")\n",
        "print(f\"Specificity: {specificity:.2%}\")\n",
        "print(f\"Execution Time: {execution_time:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO-3AeQ7LnLU",
        "outputId": "3b126b4a-3657-47c5-f6c5-d3682da3da7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-202d3db2fb02>:34: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df[['FOLLOWERS', 'ER']] = df[['FOLLOWERS', 'ER']].applymap(convert_to_numeric)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated Rankings - Key Influencers:\n",
            "                                              NAME  final_score  rank\n",
            "12                           M S Dhoni\\n@mahi7781    4878752.0   1.0\n",
            "94      Sushant Singh Rajput\\n@sushantsinghrajput    1840892.0   2.0\n",
            "467                    Ritika Sajdeh\\n@ritssajdeh    1762692.0   3.0\n",
            "75   Sidhu Moosewala (‡®Æ‡©Ç‡®∏‡©á ‡®Ü‡®≤‡®æ)\\n@sidhu_moosewala    1695432.0   4.0\n",
            "49                       ùë®ùíãùíÜùíö ùëµùíÇùíàùíÇùíì\\n@carryminati    1693472.0   5.0\n",
            "..                                            ...          ...   ...\n",
            "619         ‚ö°F I L M Y S T A A A N‚ö°\\n@filmystaaan          NaN   NaN\n",
            "628                          Sunita\\n@sunita___82          NaN   NaN\n",
            "742                     filmyakzone\\n@filmyakzone          NaN   NaN\n",
            "758                   ùêèùêëùêéùêåùêéùêìùêàùêéùêç\\n@intense.records          NaN   NaN\n",
            "874             fitness_track27\\n@fitness_track27          NaN   NaN\n",
            "\n",
            "[999 rows x 3 columns]\n",
            "\n",
            "Precision: 46.46%\n",
            "Accuracy: 88.69%\n",
            "F1-Score: 44.88%\n",
            "Recall: 43.40%\n",
            "Specificity: 94.06%\n",
            "Execution Time: 52.4148 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COSINE SIMILARITY\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import precision_score, accuracy_score, f1_score, recall_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/sample_data/insta dataset new - Sheet1 (2).csv\")\n",
        "\n",
        "# Convert necessary columns to numeric\n",
        "def convert_to_numeric(value):\n",
        "    if isinstance(value, str):\n",
        "        if '%' in value:\n",
        "            return float(value.replace('%', ''))\n",
        "        elif 'M' in value:\n",
        "            return float(value.replace('M', '')) * 1e6\n",
        "        elif 'K' in value:\n",
        "            return float(value.replace('K', '')) * 1e3\n",
        "        elif value == '-':\n",
        "            return np.nan\n",
        "        else:\n",
        "            try:\n",
        "                return float(value)\n",
        "            except ValueError:\n",
        "                return np.nan\n",
        "    return value\n",
        "\n",
        "df[['FOLLOWERS', 'ER']] = df[['FOLLOWERS', 'ER']].applymap(convert_to_numeric)\n",
        "\n",
        "# Step 1: Clustering based on engagement metrics\n",
        "start_time = time.time()\n",
        "X = df[['FOLLOWERS', 'ER']].fillna(0)\n",
        "kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "df['cluster'] = kmeans.fit_predict(X)\n",
        "clustering_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
        "\n",
        "# Step 2: Cosine Similarity Calculation\n",
        "start_time = time.time()\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(df['NAME'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix)\n",
        "df['cosine_score'] = cosine_sim.mean(axis=1)\n",
        "similarity_time = (time.time() - start_time) * 1000\n",
        "\n",
        "# Step 3: Ranking Influencers Based on Cosine Similarity\n",
        "start_time = time.time()\n",
        "df['final_score'] = df['cosine_score']\n",
        "df['predicted_rank'] = df['final_score'].rank(ascending=False)\n",
        "ranking_time = (time.time() - start_time) * 1000\n",
        "\n",
        "# Step 4: Compare with Actual Dataset Order\n",
        "start_time = time.time()\n",
        "df['actual_rank'] = df.index + 1\n",
        "\n",
        "# Define top influencers as the top 10%\n",
        "top_n = int(0.1 * len(df))\n",
        "\n",
        "df['actual_label'] = (df['actual_rank'] <= top_n).astype(int)\n",
        "df['predicted_label'] = (df['predicted_rank'] <= top_n).astype(int)\n",
        "\n",
        "# Compute Metrics\n",
        "precision = precision_score(df['actual_label'], df['predicted_label']) * 100\n",
        "accuracy = accuracy_score(df['actual_label'], df['predicted_label']) * 100\n",
        "f1 = f1_score(df['actual_label'], df['predicted_label']) * 100\n",
        "recall = recall_score(df['actual_label'], df['predicted_label']) * 100\n",
        "\n",
        "# Compute Specificity\n",
        "tn = ((df['actual_label'] == 0) & (df['predicted_label'] == 0)).sum()\n",
        "fp = ((df['actual_label'] == 0) & (df['predicted_label'] == 1)).sum()\n",
        "specificity = (tn / (tn + fp)) * 100 if (tn + fp) > 0 else 0\n",
        "metrics_time = (time.time() - start_time) * 1000\n",
        "\n",
        "# Total Execution Time\n",
        "total_execution_time = clustering_time + similarity_time + ranking_time + metrics_time\n",
        "\n",
        "# Display Results\n",
        "print(\"\\nUpdated Rankings - Key Influencers:\\n\", df[['NAME', 'final_score', 'predicted_rank']].sort_values(by='predicted_rank'))\n",
        "print(f\"\\nPrecision: {precision:.2f}%\")\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "print(f\"F1-Score: {f1:.2f}%\")\n",
        "print(f\"Recall: {recall:.2f}%\")\n",
        "print(f\"Specificity: {specificity:.2f}%\\n\")\n",
        "\n",
        "# Display execution time breakdown\n",
        "print(f\"Total Execution Time: {total_execution_time / 1000:.4f} seconds\")  # Convert ms to seconds\n",
        "print(f\"Step 1 (Clustering): {clustering_time:.2f} ms\")\n",
        "print(f\"Step 2 (Cosine Similarity Calculation): {similarity_time:.2f} ms\")\n",
        "print(f\"Step 3 (Ranking Calculation): {ranking_time:.2f} ms\")\n",
        "print(f\"Step 4 (Metrics Calculation): {metrics_time:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKtDT1jHMeNt",
        "outputId": "9c30a715-e7b8-4b4c-e332-28e2c5889321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated Rankings - Key Influencers:\n",
            "                                            NAME  final_score  predicted_rank\n",
            "88      Kareena Kapoor Khan\\n@kareenakapoorkhan     0.007850             1.5\n",
            "253  Kareena Kapoor Khan\\n@therealkareenakapoor     0.007850             1.5\n",
            "15                 Ranveer Singh\\n@ranveersingh     0.007550             3.0\n",
            "302                  Ritika Singh\\n@ritika_offl     0.007492             4.0\n",
            "932             Ankita Singh\\n@ankitasingh_2910     0.007438             5.0\n",
            "..                                          ...          ...             ...\n",
            "210        Mankirt Aulakh (‡®î‡®≤‡®ñ)\\n@mankirtaulakh     0.001001           850.0\n",
            "662                 Swami Ramdev\\n@swaamiramdev     0.001001           850.0\n",
            "659                Srishty Rode\\n@srishtyrode24     0.001001           850.0\n",
            "200                Harsh Beniwal\\n@harshbeniwal     0.001001           850.0\n",
            "691                  MANJUL KHATTAR\\n@manjullll     0.001001           850.0\n",
            "\n",
            "[999 rows x 3 columns]\n",
            "\n",
            "Precision: 17.53%\n",
            "Accuracy: 83.78%\n",
            "F1-Score: 17.35%\n",
            "Recall: 17.17%\n",
            "Specificity: 91.11%\n",
            "\n",
            "Total Execution Time: 0.0650 seconds\n",
            "Step 1 (Clustering): 28.95 ms\n",
            "Step 2 (Cosine Similarity Calculation): 21.42 ms\n",
            "Step 3 (Ranking Calculation): 1.14 ms\n",
            "Step 4 (Metrics Calculation): 13.47 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-f2771b1ea3b1>:31: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df[['FOLLOWERS', 'ER']] = df[['FOLLOWERS', 'ER']].applymap(convert_to_numeric)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# JACCARD SIMILARITY\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import jaccard_score, precision_score, accuracy_score, f1_score, recall_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/sample_data/insta dataset new - Sheet1 (2).csv\")\n",
        "\n",
        "# Convert necessary columns to numeric (handling percentage values)\n",
        "def convert_to_numeric(value):\n",
        "    if isinstance(value, str):\n",
        "        if '%' in value:\n",
        "            return float(value.replace('%', ''))\n",
        "        elif 'M' in value:\n",
        "            return float(value.replace('M', '')) * 1e6\n",
        "        elif 'K' in value:\n",
        "            return float(value.replace('K', '')) * 1e3\n",
        "        elif value == '-':  # Handle hyphens as missing values\n",
        "            return np.nan\n",
        "        else:\n",
        "            try:\n",
        "                return float(value)\n",
        "            except ValueError:\n",
        "                return np.nan  # Handle other invalid values\n",
        "    return value\n",
        "\n",
        "df[['FOLLOWERS', 'ER']] = df[['FOLLOWERS', 'ER']].applymap(convert_to_numeric)\n",
        "\n",
        "# Step 1: Jaccard Similarity Calculation\n",
        "start_time = time.time()\n",
        "\n",
        "def jaccard_similarity(a, b):\n",
        "    set_a = set(a.lower().split())\n",
        "    set_b = set(b.lower().split())\n",
        "    intersection = len(set_a.intersection(set_b))\n",
        "    union = len(set_a.union(set_b))\n",
        "    return intersection / union if union else 0\n",
        "\n",
        "df['jaccard_score'] = df['NAME'].apply(lambda x: np.mean([jaccard_similarity(x, y) for y in df['NAME']]))\n",
        "similarity_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n",
        "\n",
        "# Step 2: Assign Labels\n",
        "start_time = time.time()\n",
        "threshold_pred = df['jaccard_score'].quantile(0.90)  # Top 10% influencers by Jaccard similarity\n",
        "df['predicted_label'] = (df['jaccard_score'] >= threshold_pred).astype(int)  # 1 for influencers, 0 otherwise\n",
        "labeling_time = (time.time() - start_time) * 1000\n",
        "\n",
        "# ‚úÖ Step 3: Create Actual Labels (Ground Truth)\n",
        "start_time = time.time()\n",
        "threshold_actual = df['FOLLOWERS'].quantile(0.90)  # Top 10% influencers by Followers\n",
        "df['actual_label'] = (df['FOLLOWERS'] >= threshold_actual).astype(int)  # 1 for influencers, 0 otherwise\n",
        "ground_truth_time = (time.time() - start_time) * 1000\n",
        "\n",
        "# Step 4: Compute Precision, Accuracy, F1-score, Recall, and Specificity\n",
        "start_time = time.time()\n",
        "predicted = df['predicted_label']\n",
        "actual = df['actual_label']\n",
        "\n",
        "precision = precision_score(actual, predicted) * 100\n",
        "accuracy = accuracy_score(actual, predicted) * 100\n",
        "f1 = f1_score(actual, predicted) * 100\n",
        "recall = recall_score(actual, predicted) * 100\n",
        "\n",
        "# Compute Specificity\n",
        "tn = ((actual == 0) & (predicted == 0)).sum()\n",
        "fp = ((actual == 0) & (predicted == 1)).sum()\n",
        "specificity = (tn / (tn + fp)) * 100 if (tn + fp) > 0 else 0\n",
        "metrics_time = (time.time() - start_time) * 1000\n",
        "\n",
        "# Step 5: Ranking influencers\n",
        "start_time = time.time()\n",
        "df['rank'] = df['jaccard_score'].rank(ascending=False)\n",
        "ranking_time = (time.time() - start_time) * 1000\n",
        "\n",
        "# Total Execution Time (Convert from ms to seconds)\n",
        "total_execution_time = (similarity_time + labeling_time + ground_truth_time + metrics_time + ranking_time) / 1000\n",
        "\n",
        "# Print Metrics\n",
        "print(\"\\nUpdated Rankings - Key Influencers:\\n\", df[['NAME', 'jaccard_score', 'rank']].sort_values(by='rank'))\n",
        "print(f\"\\nPrecision: {precision:.2f}%\")\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "print(f\"F1-score: {f1:.2f}%\")\n",
        "print(f\"Recall: {recall:.2f}%\")\n",
        "print(f\"Specificity: {specificity:.2f}%\\n\")\n",
        "\n",
        "# Print Execution Time Breakdown\n",
        "print(f\"Total Execution Time: {total_execution_time:.4f} seconds\")\n",
        "print(f\"Step 1 (Jaccard Similarity Calculation): {similarity_time:.2f} ms\")\n",
        "print(f\"Step 2 (Assigning Labels): {labeling_time:.2f} ms\")\n",
        "print(f\"Step 3 (Creating Ground Truth Labels): {ground_truth_time:.2f} ms\")\n",
        "print(f\"Step 4 (Metrics Calculation): {metrics_time:.2f} ms\")\n",
        "print(f\"Step 5 (Ranking Calculation): {ranking_time:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mq6tBBFMt4l",
        "outputId": "e52b7410-88a7-448a-af34-fa8193615b3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-a80fa7c7cc41>:28: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df[['FOLLOWERS', 'ER']] = df[['FOLLOWERS', 'ER']].applymap(convert_to_numeric)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated Rankings - Key Influencers:\n",
            "                                    NAME  jaccard_score   rank\n",
            "15         Ranveer Singh\\n@ranveersingh       0.008519    1.0\n",
            "932     Ankita Singh\\n@ankitasingh_2910       0.008453    2.0\n",
            "489  Komal Singh\\n@komalsingh__official       0.008319    3.0\n",
            "837       Shweta Singh\\n@shweta_singh6_       0.008319    4.0\n",
            "637      Prabhjot Singh\\n@jatt_prabhjot       0.008219    5.5\n",
            "..                                  ...            ...    ...\n",
            "236      Hiphop Tamizha\\n@hiphoptamizha       0.001001  819.0\n",
            "237             MONALISA\\n@aslimonalisa       0.001001  819.0\n",
            "634          Melvin Louis\\n@melvinlouis       0.001001  819.0\n",
            "630      Ruhaanika Dhawann\\n@ruhaanikad       0.001001  819.0\n",
            "694         Mamta Mohandas\\n@mamtamohan       0.001001  819.0\n",
            "\n",
            "[999 rows x 3 columns]\n",
            "\n",
            "Precision: 18.00%\n",
            "Accuracy: 83.58%\n",
            "F1-score: 18.00%\n",
            "Recall: 18.00%\n",
            "Specificity: 90.88%\n",
            "\n",
            "Total Execution Time: 2.2861 seconds\n",
            "Step 1 (Jaccard Similarity Calculation): 2270.22 ms\n",
            "Step 2 (Assigning Labels): 2.50 ms\n",
            "Step 3 (Creating Ground Truth Labels): 1.58 ms\n",
            "Step 4 (Metrics Calculation): 11.08 ms\n",
            "Step 5 (Ranking Calculation): 0.74 ms\n"
          ]
        }
      ]
    }
  ]
}